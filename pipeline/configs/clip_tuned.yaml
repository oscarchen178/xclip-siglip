base_data_dir: "../pretrain_encoded"

data:
  train_image_embeddings: "train_image_embeddings.pt"
  train_text_embeddings: "train_text_embeddings.pt"
  train_metadata: "train_metadata.json"
  val_image_embeddings: "val_image_embeddings.pt"
  val_text_embeddings: "val_text_embeddings.pt"
  val_metadata: "val2017_metadata.json"
  test_image_embeddings: "test_image_embeddings.pt"
  test_text_embeddings: "test_text_embeddings.pt"
  test_metadata: "test_metadata.json"

device: auto
evaluation:
  save_features: true
  top_k:
  - 1
  - 5
  - 10
  - 50
  tsne_perplexity: 30
  visualization_samples: 5000
experiment_name: best_clip_tuning
loss:
  learnable_scale: false
  temperature: 0.04180168384065599
  type: softmax_infonce
model:
  dropout: 0.1674294123599166
  hidden_dim: 2048
  output_dim: 1024
  type: clip
output_dir: results
seed: 42
training:
  batch_size: 2048
  learning_rate: 0.00022214718099001886
  max_grad_norm: 1.0
  num_epochs: 50
  patience: 5
  weight_decay: 0.0010668051196720653
