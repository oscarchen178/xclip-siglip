# CLIP-style Configuration with Learnable Temperature

experiment_name: "clip"
output_dir: "results"
device: "auto"
seed: 42
base_data_dir: "../pretrain_encoded"

data:
  train_image_embeddings: "train_image_embeddings.pt"
  train_text_embeddings: "train_text_embeddings.pt"
  train_metadata: "train_metadata.json"
  val_image_embeddings: "val_image_embeddings.pt"
  val_text_embeddings: "val_text_embeddings.pt"
  val_metadata: "val2017_metadata.json"
  test_image_embeddings: "test_image_embeddings.pt"
  test_text_embeddings: "test_text_embeddings.pt"
  test_metadata: "test_metadata.json"

model:
  type: "clip"
  output_dim: 512
  hidden_dim: 1024          # Will default to input_dim // 2 if not specified
  dropout: 0.1

training:
  batch_size: 512
  learning_rate: 5e-4       # Higher LR for CLIP-style training
  weight_decay: 0.01
  num_epochs: 50
  patience: 5
  max_grad_norm: 1.0

loss:
  type: "softmax_infonce"              # Uses learnable temperature from model
  temperature: 0.07         # Initial temperature (will be learned)
  learnable_scale: true     # Use model's learnable logit_scale parameter

evaluation:
  top_k: [1, 5, 10, 50]
  visualization_samples: 5000
  tsne_perplexity: 30
  save_features: true